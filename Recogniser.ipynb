{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'face_recognition'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5c1e04e8ddb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'face_recognition'"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picture Recogniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWN_FACES_DIR = \"known_faces\"\n",
    "UNKNOWN_FACES_DIR = \"unknown_faces\"\n",
    "TOLERANCE = 0.6\n",
    "FRAME_THICKNESS = 3\n",
    "FONT_THICKNESS = 2\n",
    "MODEL = 'cnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading known faces...\n",
      "Loading bharath/5a0b80a5-20e4-4c00-bb39-3b81f4b56162.jpg\n",
      "Loading bharath/78ed07f8-5c86-4e63-9303-b4116fb33fc2.jpg\n",
      "Loading bharath/IMG_20190821_104316266_HDR.jpg\n",
      "Loading gangeya/DSC09049-01.jpeg\n",
      "Loading gangeya/IMG_20181117_160837524_HDR.jpg\n",
      "Loading gangeya/IMG_20181130_213828497_HDR.jpg\n",
      "Loading gangeya/IMG_20190221_183116934.jpg\n",
      "Loading gangeya/PIC.jpg\n",
      "Loading gangeya/temp_profile_image5108109817795162075.jpg\n",
      "Loading gangeya/Webp.net-resizeimage (5).jpg\n",
      "Loading harsha/03876ea5-2e6a-41c7-8048-2764255d5441.jpg\n",
      "Loading harsha/37b28e7c-437d-4155-a3ce-75da38eb676f.jpg\n",
      "Loading harsha/41e1e514-aeff-40f6-90d4-f33a69146465.jpg\n",
      "Loading harsha/4c01e4bf-f16f-4441-9ecd-dc9e48233aec.jpg\n",
      "Loading harsha/545ca7d3-ed3d-485c-81a1-35f0376064aa.jpg\n",
      "Loading harsha/5b466ac1-d8f0-49f6-b8d4-0dbe12d53e02.jpg\n",
      "Loading harsha/65b68fca-81df-452e-acb5-97354032d2c9.jpg\n",
      "Loading harsha/68641a93-f59f-4f5f-bf0b-f6802d3da342.jpg\n",
      "Loading harsha/74c42788-1d5a-47aa-9942-21ff51e4dcab.jpg\n",
      "Loading harsha/7db4c086-0fe8-4d7d-b45d-c8ba3e3c4039.jpg\n",
      "Loading harsha/91c36726-24c6-45f7-b7f4-1e742d51d831.jpg\n",
      "Loading harsha/b46598e3-e2c2-402a-8bab-bf064fcf4890.jpg\n",
      "Loading harsha/d8911b6f-7838-4d93-9d6d-8cfd4633ffa3.jpg\n",
      "Loading harsha/d912dc56-fd63-4b61-a3dc-2bb7e9cf18cf.jpg\n",
      "Loading harsha/IMG-20190928-WA0008.jpg\n",
      "Loading harsha/Screenshot_20191005-125602.png\n",
      "Loading jahnavi/41785e0f-5c64-46a8-991d-36d148e9a723.jpg\n",
      "Loading jahnavi/556d314a-c038-43f0-b021-7aa2e0ff09b1.jpg\n",
      "Loading jahnavi/e822771f-680c-4f21-822b-19814a8661cf.jpg\n",
      "Loading jahnavi/IMG_20191203_134456872_HDR.jpg\n",
      "Loading jahnavi/PicsArt_04-25-12.36.37.jpg\n",
      "Loading pavan/2017-01-03-15-09-08-417.jpg\n",
      "Loading pavan/IMG-20180601-WA0002.jpg\n",
      "Loading pavan/IMG_20171017_204532902_HDR.jpg\n",
      "Loading pavan/IMG_20171028_181530141.jpg\n",
      "Loading pavan/IMG_20181105_152826569.jpg\n",
      "Loading pavan/Screenshot_20181217-210331.png\n",
      "Loading satyasai/pic1.jpg\n",
      "Loading satyasai/pic2.jpg\n",
      "Loading siva/28c26c42-4d45-479a-b451-2621ac3c779f.jpg\n",
      "Loading siva/56fc8568-4ecd-45af-ba6f-ec96ec12d351.jpg\n",
      "Loading siva/ccfe2bf5-4aa5-4bae-9bf1-eb3cad82e852.jpg\n",
      "Loading siva/DSC_2185.JPG\n",
      "Loading siva/IMG_20190308_173157890_HDR.jpg\n",
      "Loading siva/IMG_20190628_003138.jpg\n",
      "Loading siva/IMG_20190727_130718951_HDR.jpg\n",
      "Loading siva/IMG_20190815_220553242_BURST000_COVER_TOP.jpg\n",
      "Loading siva/IMG_3561.JPG\n",
      "Loading siva/Screenshot_20190718-230206.png\n",
      "Process unknown faces...\n",
      "IMG_20180807_220337189.jpg\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'getName' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d5ecf6a7d623>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mmatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0mmatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknown_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf' - {match} from {results}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'getName' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Loading known faces...\")\n",
    "\n",
    "known_faces = []\n",
    "known_names = []\n",
    "\n",
    "for name in os.listdir(KNOWN_FACES_DIR):\n",
    "    #print(\"\\rLoading \"+name)\n",
    "    for filename in os.listdir(f\"{KNOWN_FACES_DIR}/{name}\"):\n",
    "        print(\"Loading \"+name+\"/\"+filename)\n",
    "        image = face_recognition.load_image_file(f\"{KNOWN_FACES_DIR}/{name}/{filename}\")\n",
    "        enc = face_recognition.face_encodings(image)[0]\n",
    "        known_faces.append(enc)\n",
    "        known_names.append(name)\n",
    "        \n",
    "print(\"Process unknown faces...\")\n",
    "\n",
    "for filename in os.listdir(UNKNOWN_FACES_DIR):\n",
    "    print(filename)\n",
    "    image = face_recognition.load_image_file(f\"{UNKNOWN_FACES_DIR}/{filename}\")\n",
    "    locations = face_recognition.face_locations(image, model=MODEL)\n",
    "    encodings = face_recognition.face_encodings(image, locations)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    for face_encoding, face_location in zip(encodings, locations):\n",
    "        results = face_recognition.compare_faces(known_faces, face_encoding, TOLERANCE)\n",
    "        match = None\n",
    "        if True in results:\n",
    "            match = getName(known_names, results)\n",
    "            print(f' - {match} from {results}')\n",
    "            \n",
    "            top_left = (face_location[3], face_location[0])\n",
    "            bottom_right = (face_location[1], face_location[2])\n",
    "            \n",
    "            color = [0, 255, 0]\n",
    "            \n",
    "            cv2.rectangle(image, top_left, bottom_right, color, FRAME_THICKNESS)\n",
    "            \n",
    "            top_left = (face_location[3], face_location[2])\n",
    "            bottom_right = (face_location[1], face_location[2]+22)\n",
    "            \n",
    "            cv2.rectangle(image, top_left, bottom_right, color, cv2.FILLED)\n",
    "            cv2.putText(image, match, (face_location[3]+10, face_location[2]+15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,200,200), FONT_THICKNESS)\n",
    "    cv2.imshow(filename, image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Process unknown faces\")\n",
    "\n",
    "for filename in os.listdir(UNKNOWN_FACES_DIR):\n",
    "    print(filename)\n",
    "    image = face_recognition.load_image_file(f\"{UNKNOWN_FACES_DIR}/{filename}\")\n",
    "    locations = face_recognition.face_locations(image, model=MODEL)\n",
    "    encodings = face_recognition.face_encodings(image, locations)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    for face_encoding, face_location in zip(encoding, locations):\n",
    "        results = face_recognition.compare_faces(known_faces, face_encoding, TOLERANCE)\n",
    "        match = None\n",
    "        if True in results:\n",
    "            match = known_names[results.index(True)]\n",
    "            print(\"Match found: {match}\")\n",
    "            \n",
    "            top_left = (face_location[3], face_location[0])\n",
    "            bottom_right = (face_location[1], face_location[2])\n",
    "            \n",
    "            color = [0, 255, 0]\n",
    "            \n",
    "            cv2.rectangle(image, top_left, bottom_right, color, FRAME_THICKNESS)\n",
    "            \n",
    "            top_left = (face_location[3], face_location[2])\n",
    "            bottom_right = (face_location[1], face_location[2]+22)\n",
    "            \n",
    "            cv2.rectangle(image, top_left, bottom_right, color, cv2.FILLED)\n",
    "            cv2.putText(image, match, (face_location[3]+10, face_location[2]+15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,200,200), FONT_THICKNESS)\n",
    "    cv2.imshow(filename, image)\n",
    "    cv2.waitKey(2000)\n",
    "    cv2.destroyWindow(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.18521494,  0.13436912,  0.06426698, -0.01019022,  0.03231701,\n",
      "        0.00670375,  0.01399652, -0.00740389,  0.17975426, -0.07496859,\n",
      "        0.17041798,  0.00492911, -0.15923157, -0.15240483, -0.0145799 ,\n",
      "        0.12326877, -0.11901758, -0.19208324, -0.13198976, -0.0588598 ,\n",
      "       -0.01950443,  0.01694503,  0.06421359,  0.00657933, -0.11737452,\n",
      "       -0.38026565, -0.04015565, -0.09271452,  0.0139049 , -0.08897686,\n",
      "       -0.01078162,  0.0370546 , -0.18716142, -0.02978755, -0.04308405,\n",
      "        0.10462825,  0.01025078, -0.00107837,  0.21818462, -0.01685355,\n",
      "       -0.16335025, -0.00335144,  0.06968772,  0.32928172,  0.12624475,\n",
      "       -0.004086  , -0.03637245, -0.00564159,  0.10583187, -0.16803767,\n",
      "        0.11399461,  0.11412528,  0.18069825,  0.07233129,  0.0791706 ,\n",
      "       -0.10132764,  0.05054976,  0.0791323 , -0.17037372,  0.06443502,\n",
      "       -0.04080179, -0.07881173, -0.07213399,  0.00297711,  0.24819183,\n",
      "        0.14243539, -0.08124749, -0.17106436,  0.13943778, -0.09551124,\n",
      "        0.00964709,  0.08292875, -0.09944844, -0.12070388, -0.30503821,\n",
      "        0.08185676,  0.31678328,  0.10012794, -0.2196064 ,  0.0345616 ,\n",
      "       -0.08777317, -0.02621504,  0.04264361,  0.11708273, -0.1940161 ,\n",
      "        0.05515865, -0.14748074,  0.01576499,  0.14268522,  0.06300384,\n",
      "       -0.16290899,  0.14010577,  0.05207788,  0.0180552 ,  0.04754075,\n",
      "       -0.01406739, -0.07991027, -0.03126187, -0.17473742, -0.04998126,\n",
      "        0.10215204, -0.05469248, -0.06925597,  0.09958185, -0.12733792,\n",
      "        0.09063707,  0.04929646,  0.01723903,  0.04427289,  0.12399196,\n",
      "       -0.10540251, -0.12590232,  0.07607828, -0.22098617,  0.15849197,\n",
      "        0.13006008,  0.03109157,  0.15081586,  0.12955248,  0.08967306,\n",
      "        0.0028053 ,  0.06092154, -0.09330797, -0.03048355,  0.0991162 ,\n",
      "        0.02858275,  0.11416657,  0.09740371])]\n"
     ]
    }
   ],
   "source": [
    "img = face_recognition.load_image_file(\"known_faces/gangeya/IMG_20181130_213828497_HDR.jpg\")\n",
    "print(face_recognition.face_encodings(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gangeya',\n",
       " 'gangeya',\n",
       " 'gangeya',\n",
       " 'gangeya',\n",
       " 'gangeya',\n",
       " 'gangeya',\n",
       " 'harsha',\n",
       " 'harsha',\n",
       " 'harsha',\n",
       " 'harsha',\n",
       " 'harsha',\n",
       " 'harsha',\n",
       " 'harsha',\n",
       " 'harsha',\n",
       " 'harsha',\n",
       " 'harsha',\n",
       " 'jahnavi',\n",
       " 'jahnavi',\n",
       " 'pavan',\n",
       " 'pavan',\n",
       " 'pavan',\n",
       " 'pavan',\n",
       " 'pavan',\n",
       " 'pavan',\n",
       " 'satyasai',\n",
       " 'satyasai']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDup(lis):\n",
    "    res = [i for n, i in enumerate(lis) if i not in lis[:n]]\n",
    "    return res;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getName(names, predictions):\n",
    "    name_lis = removeDup(names)\n",
    "    score = [0]*len(name_lis)\n",
    "    actual = [0]*len(name_lis)\n",
    "    for name, prediction in zip(names, predictions):\n",
    "        if(prediction):\n",
    "            score[name_lis.index(name)] += 1\n",
    "        actual[name_lis.index(name)] += 1\n",
    "    for i in range(len(score)):\n",
    "        score[i] = score[i]/actual[i]\n",
    "    if(score[score.index(max(score))] > 0.80):\n",
    "        return name_lis[score.index(max(score))]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process unknown faces...\n",
      "IMG_20180807_220337189.jpg\n",
      " - satyasai from [False, False, False, False, False, True, False, False, False, True, False, False, False, False, False, True, False, False, False, False, False, True, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, True, True, True, False, False, True, False, True, False, False, False, True]\n",
      " - gangeya from [True, False, False, True, True, True, True, True, True, True, False, False, True, False, False, True, False, False, False, False, False, True, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, True, False, False, False, False, False, False]\n",
      " - pavan from [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      " - bharath from [True, True, True, False, True, True, False, True, False, True, True, True, True, True, False, True, True, False, True, False, False, True, True, False, True, True, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, True, True, True, False, False, False, True]\n"
     ]
    }
   ],
   "source": [
    "print(\"Process unknown faces...\")\n",
    "\n",
    "for filename in os.listdir(UNKNOWN_FACES_DIR):\n",
    "    print(filename)\n",
    "    image = face_recognition.load_image_file(f\"{UNKNOWN_FACES_DIR}/{filename}\")\n",
    "    locations = face_recognition.face_locations(image, model=MODEL)\n",
    "    encodings = face_recognition.face_encodings(image, locations)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    for face_encoding, face_location in zip(encodings, locations):\n",
    "        results = face_recognition.compare_faces(known_faces, face_encoding, TOLERANCE)\n",
    "        match = None\n",
    "        if True in results:\n",
    "            match = getName(known_names, results)\n",
    "            print(f' - {match} from {results}')\n",
    "            \n",
    "            top_left = (face_location[3], face_location[0])\n",
    "            bottom_right = (face_location[1], face_location[2])\n",
    "            \n",
    "            color = [0, 255, 0]\n",
    "            \n",
    "            cv2.rectangle(image, top_left, bottom_right, color, FRAME_THICKNESS)\n",
    "            \n",
    "            top_left = (face_location[3], face_location[2])\n",
    "            bottom_right = (face_location[1], face_location[2]+22)\n",
    "            \n",
    "            cv2.rectangle(image, top_left, bottom_right, color, cv2.FILLED)\n",
    "            cv2.putText(image, match, (face_location[3]+10, face_location[2]+15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,200,200), FONT_THICKNESS)\n",
    "    cv2.imshow(filename, image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
